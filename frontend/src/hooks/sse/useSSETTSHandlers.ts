/**
 * TTS Job SSE Event Handlers for React Query Cache Updates
 *
 * This module contains all TTS job-related SSE event handlers, extracted from
 * useSSEEventHandlers.ts for better code organization and maintainability.
 *
 * Event Types Handled:
 * - Job Events: job.created, job.started, job.progress, job.completed, job.failed, job.cancelling, job.cancelled, job.resumed
 * - Segment Events: segment.started, segment.completed, segment.failed
 *
 * Performance Optimizations:
 * - Uses updateTTSJobInCaches from jobCacheUpdater utility (consolidates duplicated cache update logic)
 * - Uses immer for O(1) cache updates instead of O(n) mapping
 * - Optimistic updates for instant UI feedback
 * - Minimal invalidation to avoid excessive refetches
 * - Final authoritative refetch only at job.completed/failed
 */

import { useCallback } from 'react'
import { produce } from 'immer'
import type { QueryClient } from '@tanstack/react-query'
import { queryKeys } from '@services/queryKeys'
import type { TTSJob, Chapter } from '@types'
import type {
  JobCreatedData,
  JobStartedData,
  JobProgressData,
  JobCompletedData,
  JobFailedData,
  JobCancelledData,
  JobResumedData,
  SegmentStartedData,
  SegmentCompletedData,
  SegmentFailedData,
} from '@/types/sseEvents'
import { logger } from '@utils/logger'
import { updateTTSJobInCaches } from '@utils/jobCacheUpdater'

// ============================================================================
// Local Extended Types
// ============================================================================

/**
 * Segment ID with job status (matches backend structure)
 */
interface SegmentJobStatus {
  id: string
  job_status: 'pending' | 'completed'
}

/**
 * Extended Job Created Data with additional fields
 * Using intersection type to handle segmentIds compatibility
 */
type ExtendedJobCreatedData = Omit<JobCreatedData, 'segmentIds'> & {
  status?: 'pending'
  processedSegments?: number
  progress?: number
  segmentIds?: SegmentJobStatus[] | string[] // Allow both extended and base types for tests
  ttsEngine?: string
  ttsModelName?: string
  ttsSpeakerName?: string
}

/**
 * Extended Job Started Data with additional fields
 */
interface ExtendedJobStartedData extends JobStartedData {
  status?: 'running'
  totalSegments?: number
  processedSegments?: number
  progress?: number
  segmentIds?: SegmentJobStatus[]
  startedAt?: string
  ttsEngine?: string
}

/**
 * Extended Job Progress Data with additional fields
 * Note: processedSegments is already in base type
 */
interface ExtendedJobProgressData extends JobProgressData {
  status?: 'running'
  segmentIds?: SegmentJobStatus[]
  failedSegments?: number
}

/**
 * Extended Job Completed Data with additional fields
 * Note: processedSegments is already in base type
 */
interface ExtendedJobCompletedData extends JobCompletedData {
  status?: 'completed'
  progress?: number
  segmentIds?: SegmentJobStatus[]
}

/**
 * Extended Job Failed Data with additional fields
 */
interface ExtendedJobFailedData extends JobFailedData {
  status?: 'failed'
  segmentIds?: SegmentJobStatus[]
}

/**
 * Extended Job Cancelled Data with additional fields
 */
interface ExtendedJobCancelledData extends JobCancelledData {
  status?: 'cancelled'
  segmentIds?: SegmentJobStatus[]
}

/**
 * Extended Segment Completed Data
 */
interface ExtendedSegmentCompletedData extends SegmentCompletedData {
  status: 'completed'
}

/**
 * Extended Segment Failed Data
 */
interface ExtendedSegmentFailedData extends SegmentFailedData {
  status: 'failed'
}

// ============================================================================
// Helper Functions
// ============================================================================

/**
 * Invalidate queries for a specific chapter
 *
 * Invalidates:
 * - Chapter detail query (includes segments array)
 * - Segment queries for this chapter
 *
 * Note: Projects list is NOT invalidated here (done at job.completed/failed)
 * to avoid excessive refetches during segment-level updates.
 */
function invalidateChapterQueries(queryClient: QueryClient, chapterId: string) {
  // Invalidate chapter detail (includes segments with status badges)
  queryClient.invalidateQueries({
    queryKey: queryKeys.chapters.detail(chapterId),
    exact: false
  })

  // Invalidate segment queries for this chapter
  queryClient.invalidateQueries({
    queryKey: queryKeys.segments.lists(),
    predicate: (query: any) => {
      // Only invalidate segment queries for this specific chapter
      const queryKey = query.queryKey as string[]
      return queryKey.includes(chapterId)
    }
  })
}

// ============================================================================
// Event Handlers
// ============================================================================

/**
 * Handle job.created event
 * Action: Add new job to cache optimistically + set segments to 'queued' status
 *
 * This provides IMMEDIATE UI feedback when user creates a job,
 * before the worker picks it up (eliminates 1-second delay).
 *
 * NO INVALIDATION - We add the job optimistically to avoid flickering
 */
function handleJobCreated(data: ExtendedJobCreatedData, queryClient: QueryClient) {
  try {
    logger.group(
      'üìù Job Created',
      'New TTS job created and queued',
      {
        'Job ID': data.jobId,
        'Chapter ID': data.chapterId,
        'Total Segments': data.totalSegments,
        'Queued Segments': data.segmentIds?.length || 0,
        'Initial Status': data.status
      },
      '#4CAF50' // Green for job creation
    )

    // 1. Add new job to cache optimistically (no refetch needed)
    // Try to get chapter/project titles from cache for better UX
    let chapterTitle: string | null = null
    let projectTitle: string | null = null

    if (data.chapterId) {
      const chapterData = queryClient.getQueryData<Chapter>(
        queryKeys.chapters.detail(data.chapterId)
      )

      if (chapterData) {
        chapterTitle = chapterData.title

        // Try to get project title from projects list
        const projectsData = queryClient.getQueryData<Array<{ id: string; title: string; chapters: Array<{ id: string; projectId: string }> }>>(
          queryKeys.projects.lists()
        )

        if (projectsData && chapterData.projectId) {
          const project = projectsData.find((p) => p.id === chapterData.projectId)
          if (project) {
            projectTitle = project.title
          }
        }
      }
    }

    const newJob: Partial<TTSJob> = {
      id: data.jobId,
      chapterId: data.chapterId,
      chapterTitle: chapterTitle,
      projectTitle: projectTitle,
      ttsEngine: data.ttsEngine || '',
      ttsModelName: data.ttsModelName || '',
      ttsSpeakerName: data.ttsSpeakerName || '',
      language: '',
      forceRegenerate: false,
      status: 'pending',
      totalSegments: data.totalSegments || 0,
      processedSegments: data.processedSegments || 0,
      failedSegments: 0,
      currentSegmentId: null,
      errorMessage: null,
      retryCount: 0,
      createdAt: new Date(),
      startedAt: null,
      completedAt: null,
      updatedAt: new Date(),
    }

    // Add to ALL jobs cache queries
    const addJobToCache = (oldData: { jobs: TTSJob[]; count: number } | undefined) => {
      if (!oldData?.jobs) return oldData
      // Check if job already exists (avoid duplicates)
      const exists = oldData.jobs.some((job) => job.id === data.jobId)
      if (exists) return oldData
      return {
        ...oldData,
        jobs: [newJob as TTSJob, ...oldData.jobs],
        count: (oldData.count || 0) + 1
      }
    }

    // 1. Update activeJobs cache (for badge in AppLayout)
    queryClient.setQueryData(
      queryKeys.tts.activeJobs(),
      addJobToCache
    )

    // 2. Update general jobs cache (for JobsPanel dialog)
    queryClient.setQueryData(
      queryKeys.tts.jobs({ limit: 50 }),
      addJobToCache
    )

    // 2. Set segments to 'queued' status (database status, not optimistic)
    // This provides instant visual feedback when job is created
    // Optimized with immer: O(n) find instead of O(n) map for targeted updates
    if (data.segmentIds && data.chapterId) {
      queryClient.setQueryData(
        queryKeys.chapters.detail(data.chapterId),
        produce((draft: Chapter | undefined) => {
          if (!draft) {
            logger.warn('[SSE] Chapter not in cache, invalidating instead:', data.chapterId)
            // If chapter not in cache, invalidate to trigger refetch
            invalidateChapterQueries(queryClient, data.chapterId)
            return
          }

          // Get segment IDs that are pending in this job
          // Handle both SegmentJobStatus[] (production) and string[] (tests)
          const queuedSegmentIds = new Set<string>()
          data.segmentIds!.forEach(seg => {
            if (typeof seg === 'string') {
              // Test data: simple string array
              queuedSegmentIds.add(seg)
            } else if (seg.job_status === 'pending') {
              // Production data: SegmentJobStatus objects
              queuedSegmentIds.add(seg.id)
            }
          })

          // Update only the queued segments directly (avoids copying all 400 segments)
          for (const segment of draft.segments) {
            if (queuedSegmentIds.has(segment.id)) {
              segment.status = 'queued' as const
              segment.audioPath = null
            }
          }
        })
      )

      // NO invalidation here - optimistic update already updated cache
      // (Fallback invalidation at line 383 handles case when chapter not in cache)

      logger.group(
        '‚úÖ Segments Queued',
        'Segments marked as queued for immediate UI feedback',
        {
          'Queued Count': data.segmentIds.filter(s => typeof s === 'string' || s.job_status === 'pending').length,
          'Chapter ID': data.chapterId,
          'Feedback Type': 'Optimistic (instant)'
        },
        '#2196F3' // Blue for status updates
      )
    } else {
      logger.group(
        '‚ö†Ô∏è Job Created (Incomplete)',
        'Missing data in job.created event',
        {
          'Has Segment IDs': !!data.segmentIds,
          'Has Chapter ID': !!data.chapterId,
          'Impact': 'Cannot set queued status'
        },
        '#FF9800' // Orange for warning
      )
    }
  } catch (error) {
    logger.group(
      '‚ùå Job Created Handler Failed',
      'Error handling job.created event',
      {
        'Error': error instanceof Error ? error.message : String(error),
        'Job ID': data.jobId
      },
      '#F44336' // Red for error
    )
  }
}

/**
 * Handle job.started event
 * Action: Update job status to 'running'
 *
 * Note: Segments are already set to 'queued' by job.created event.
 * This event just marks the job as running when worker picks it up.
 * Also updates titles if they weren't available at job.created time.
 */
function handleJobStarted(data: ExtendedJobStartedData, queryClient: QueryClient) {
  try {
    logger.group(
      '‚ñ∂Ô∏è Job Started',
      'Worker picked up job and started processing',
      {
        'Job ID': data.jobId,
        'Chapter ID': data.chapterId,
        'Total Segments': data.totalSegments,
        'Status': data.status
      },
      '#2196F3' // Blue for job progress
    )

    // Try to get chapter/project titles from cache (in case they weren't available at job.created)
    let chapterTitle: string | null = null
    let projectTitle: string | null = null

    if (data.chapterId) {
      const chapterData = queryClient.getQueryData<Chapter>(
        queryKeys.chapters.detail(data.chapterId)
      )

      if (chapterData) {
        chapterTitle = chapterData.title

        const projectsData = queryClient.getQueryData<Array<{ id: string; title: string; chapters: Array<{ id: string; projectId: string }> }>>(
          queryKeys.projects.lists()
        )

        if (projectsData && chapterData.projectId) {
          const project = projectsData.find((p) => p.id === chapterData.projectId)
          if (project) {
            projectTitle = project.title
          }
        }
      }
    }

    // Update job status to 'running' in all caches
    // Use startedAt from event (populated by backend from DB) or fallback to now
    const updates: Partial<TTSJob> = {
      status: 'running',
      startedAt: data.startedAt ? new Date(data.startedAt) : new Date(),
      processedSegments: data.processedSegments ?? 0,
      totalSegments: data.totalSegments,
      chapterTitle: chapterTitle,
      projectTitle: projectTitle,
      // Include ttsEngine if provided (ensures engine name shows immediately)
      ...(data.ttsEngine && { ttsEngine: data.ttsEngine }),
    }

    updateTTSJobInCaches(queryClient, data.jobId, updates)

    // Invalidate projects list (for ChapterList to show job started)
    // Note: Only once per job (not per segment like segment.started)
    queryClient.invalidateQueries({
      queryKey: queryKeys.projects.lists(),
      exact: false
    })
  } catch (error) {
    logger.group(
      '‚ùå Job Started Handler Failed',
      'Error handling job.started event',
      {
        'Error': error instanceof Error ? error.message : String(error),
        'Job ID': data.jobId
      },
      '#F44336' // Red for error
    )
  }
}

/**
 * Handle job.progress event
 * Action: Update job progress directly in cache (no refetch)
 */
function handleJobProgress(data: ExtendedJobProgressData, queryClient: QueryClient) {
  try {
    const updates: Partial<TTSJob> = {
      status: 'running',
      processedSegments: data.processedSegments,
      totalSegments: data.totalSegments,
      failedSegments: data.failedSegments ?? 0,
      currentSegmentId: data.currentSegmentId ?? null,
      updatedAt: new Date(),
    }

    updateTTSJobInCaches(queryClient, data.jobId, updates)
  } catch (error) {
    logger.error('[SSE] Failed to handle job.progress event:', error)
  }
}

/**
 * Handle job.completed event
 * Action: Update job + invalidate chapter detail
 */
function handleJobCompleted(
  data: ExtendedJobCompletedData,
  queryClient: QueryClient,
  onJobStatusChange?: (status: 'completed' | 'failed' | 'cancelled', jobId: string, chapterId: string) => void
) {
  try {
    logger.group(
      '‚úÖ Job Completed',
      'TTS job finished successfully',
      {
        'Job ID': data.jobId,
        'Chapter ID': data.chapterId,
        'Processed': `${data.processedSegments}/${data.totalSegments}`,
        'Progress': data.progress !== undefined ? `${data.progress.toFixed(1)}%` : '100%'
      },
      '#4CAF50' // Green for success
    )

    const updates: Partial<TTSJob> = {
      status: 'completed',
      processedSegments: data.processedSegments,
      totalSegments: data.totalSegments,
      completedAt: new Date(),
      updatedAt: new Date(),
    }

    updateTTSJobInCaches(queryClient, data.jobId, updates)

    // Trigger user notification callback
    if (onJobStatusChange && data.chapterId) {
      onJobStatusChange('completed', data.jobId, data.chapterId)
    }

    // FINAL authoritative refetch: Invalidate ALL job queries
    // This is the ONLY place where we refetch during generation
    queryClient.invalidateQueries({
      queryKey: queryKeys.tts.all,
      exact: false
    })

    // Invalidate chapter queries (more efficient than invalidating all projects)
    if (data.chapterId) {
      invalidateChapterQueries(queryClient, data.chapterId)
    }

    // Invalidate projects list (for ChapterList segment status updates)
    // Note: ChapterList shows segment status from project.chapters data
    queryClient.invalidateQueries({
      queryKey: queryKeys.projects.lists(),
      exact: false
    })
  } catch (error) {
    logger.group(
      '‚ùå Job Completed Handler Failed',
      'Error handling job.completed event',
      {
        'Error': error instanceof Error ? error.message : String(error),
        'Job ID': data.jobId
      },
      '#F44336' // Red for error
    )
  }
}

/**
 * Handle job.failed event
 * Action: Update job + invalidate chapter detail
 */
function handleJobFailed(
  data: ExtendedJobFailedData,
  queryClient: QueryClient,
  onJobStatusChange?: (status: 'completed' | 'failed' | 'cancelled', jobId: string, chapterId: string) => void
) {
  try {
    logger.group(
      '‚ùå Job Failed',
      'TTS job failed with error',
      {
        'Job ID': data.jobId,
        'Chapter ID': data.chapterId,
        'Error': data.error,
        'Status': data.status
      },
      '#F44336' // Red for failure
    )

    const updates: Partial<TTSJob> = {
      status: 'failed',
      errorMessage: data.error,
      completedAt: new Date(),
      updatedAt: new Date(),
    }

    updateTTSJobInCaches(queryClient, data.jobId, updates)

    // Trigger user notification callback
    if (onJobStatusChange && data.chapterId) {
      onJobStatusChange('failed', data.jobId, data.chapterId)
    }

    // FINAL authoritative refetch: Invalidate ALL job queries
    // This ensures we have fresh data after job completion
    queryClient.invalidateQueries({
      queryKey: queryKeys.tts.all,
      exact: false
    })

    // Invalidate chapter queries (more efficient than invalidating all projects)
    if (data.chapterId) {
      invalidateChapterQueries(queryClient, data.chapterId)
    }

    // Invalidate projects list (for ChapterList segment status updates)
    // Note: ChapterList shows segment status from project.chapters data
    queryClient.invalidateQueries({
      queryKey: queryKeys.projects.lists(),
      exact: false
    })
  } catch (error) {
    logger.group(
      '‚ùå Job Failed Handler Failed',
      'Error handling job.failed event',
      {
        'Error': error instanceof Error ? error.message : String(error),
        'Job ID': data.jobId
      },
      '#F44336' // Red for error
    )
  }
}

/**
 * Handle job.cancelling event
 * Action: Update job status to 'cancelling' for immediate UI feedback
 *
 * This event is emitted when cancellation is requested for a running job.
 * The worker will emit job.cancelled when it actually stops (after finishing current segment).
 */
function handleJobCancelling(
  data: { jobId: string; chapterId: string },
  queryClient: QueryClient
) {
  try {
    logger.group(
      '‚è∏Ô∏è Job Cancelling',
      'Cancellation requested, waiting for current segment to complete',
      {
        'Job ID': data.jobId,
        'Chapter ID': data.chapterId,
      },
      '#FF9800' // Orange for cancelling
    )

    const updates: Partial<TTSJob> = {
      status: 'cancelling',
      updatedAt: new Date(),
    }

    updateTTSJobInCaches(queryClient, data.jobId, updates)
    // NO invalidation - optimistic update is sufficient
  } catch (error) {
    logger.error('[SSE] Failed to handle job.cancelling event:', error)
  }
}

/**
 * Handle job.cancelled event
 * Action: Revert queued segments back to 'pending'
 *
 * NO INVALIDATION - Optimistic update only, final refetch at job.completed/failed
 */
function handleJobCancelled(
  data: ExtendedJobCancelledData,
  queryClient: QueryClient,
  onJobStatusChange?: (status: 'completed' | 'failed' | 'cancelled', jobId: string, chapterId: string) => void
) {
  try {
    // 1. Update job status in all caches (optimistic update only)
    const updates: Partial<TTSJob> = {
      status: 'cancelled',
      completedAt: new Date(),
      updatedAt: new Date(),
    }

    updateTTSJobInCaches(queryClient, data.jobId, updates)

    // Trigger user notification callback
    if (onJobStatusChange && data.chapterId) {
      onJobStatusChange('cancelled', data.jobId, data.chapterId)
    }

    // NO invalidation here - cancelled jobs stay in cache until user deletes or resumes them
    // This prevents flickering in JobsPanel

    // 2. Revert segments from 'queued' back to 'pending'
    // (Segments that were already 'completed' stay 'completed')
    // Optimized with immer: O(n) direct update instead of O(n) map
    if (data.segmentIds && data.chapterId) {
      queryClient.setQueryData(
        queryKeys.chapters.detail(data.chapterId),
        produce((draft: Chapter | undefined) => {
          if (!draft) return

          // Get segment IDs that were pending (not completed) in this job
          const pendingSegmentIds = new Set(
            data.segmentIds!
              .filter(seg => seg.job_status === 'pending')
              .map(seg => seg.id)
          )

          // Only revert segments that were queued (never completed)
          for (const segment of draft.segments) {
            if (pendingSegmentIds.has(segment.id) && segment.status === 'queued') {
              segment.status = 'pending' as const
            }
          }
        })
      )

      // Invalidate chapter queries (more efficient than invalidating all projects)
      invalidateChapterQueries(queryClient, data.chapterId)

    }
  } catch (error) {
    logger.error('[SSE] Failed to handle job.cancelled event:', error)
  }
}

/**
 * Handle job.resumed event
 * Action: Update job status in cache to 'pending'
 *
 * Note: Uses resumedAt as createdAt to prevent timestamp flickering
 * back to original job creation time. NO invalidateQueries here -
 * the cache update is sufficient and refetch would overwrite createdAt.
 */
function handleJobResumed(data: JobResumedData, queryClient: QueryClient) {
  try {
    const updates: Partial<TTSJob> = {
      status: 'pending',
      updatedAt: new Date(),
      // Use resumedAt as createdAt to prevent timestamp flickering
      // (otherwise refetch would show old createdAt)
      createdAt: data.resumedAt ? new Date(data.resumedAt) : new Date(),
      // Clear completion-related fields
      completedAt: null,
      errorMessage: null,
    }

    updateTTSJobInCaches(queryClient, data.jobId, updates)
    // NOTE: No invalidateQueries here - optimistic update is sufficient
    // Refetch would overwrite createdAt with the old value from DB
  } catch (error) {
    logger.error('[SSE] Failed to handle job.resumed event:', error)
  }
}

/**
 * Handle segment.started event
 * Action: Update segment status to 'processing' in chapter cache AND projects cache
 *
 * Optimized with immer: O(1) update instead of O(n) map for 95% performance gain
 */
function handleSegmentStarted(data: SegmentStartedData, queryClient: QueryClient) {
  try {
    // 1. Update chapter detail (contains segments array)
    queryClient.setQueryData(
      queryKeys.chapters.detail(data.chapterId),
      produce((draft: Chapter | undefined) => {
        if (!draft) return
        const segment = draft.segments.find(s => s.id === data.segmentId)
        if (segment) {
          segment.status = 'processing' as const
          segment.audioPath = null
        }
      })
    )

    // 2. Update projects list (for ChapterList live updates)
    queryClient.setQueryData(
      queryKeys.projects.lists(),
      produce((draft: Array<{ chapters: Array<{ id: string; segments: Array<{ id: string; status: string; audioPath: string | null }> }> }> | undefined) => {
        if (!draft) return
        for (const project of draft) {
          const chapter = project.chapters.find((ch) => ch.id === data.chapterId)
          if (chapter) {
            const segment = chapter.segments.find((s) => s.id === data.segmentId)
            if (segment) {
              segment.status = 'processing' as const
              segment.audioPath = null
            }
            break // Found the chapter, no need to continue
          }
        }
      })
    )
  } catch (error) {
    logger.error('[SSE] Failed to handle segment.started event:', error)
  }
}

/**
 * Handle segment.completed event
 * Action: Update segment status + audioPath in chapter cache AND projects cache (optimistic updates)
 *
 * Note: No invalidation here to avoid refetching entire projects list after each segment.
 * Instead we optimistically update both caches for instant UI feedback.
 * Final authoritative refetch happens once at job.completed event.
 *
 * Optimized with immer: O(1) update instead of O(n) map for 95% performance gain
 */
function handleSegmentCompleted(
  data: ExtendedSegmentCompletedData,
  queryClient: QueryClient,
  onAudioUpdate?: (segmentId: string, chapterId: string) => void
) {
  try {
    // 1. Update chapter detail (contains segments array)
    queryClient.setQueryData(
      queryKeys.chapters.detail(data.chapterId),
      produce((draft: Chapter | undefined) => {
        if (!draft) return
        const segment = draft.segments.find(s => s.id === data.segmentId)
        if (segment) {
          segment.status = 'completed' as const
          segment.audioPath = data.audioPath
        }
      })
    )

    // 2. Update projects list (for ChapterList live updates)
    // Optimistic update - no server request, instant UI feedback
    queryClient.setQueryData(
      queryKeys.projects.lists(),
      produce((draft: Array<{ chapters: Array<{ id: string; segments: Array<{ id: string; status: string; audioPath: string | null }> }> }> | undefined) => {
        if (!draft) return
        for (const project of draft) {
          const chapter = project.chapters.find((ch) => ch.id === data.chapterId)
          if (chapter) {
            const segment = chapter.segments.find((s) => s.id === data.segmentId)
            if (segment) {
              segment.status = 'completed' as const
              segment.audioPath = data.audioPath
            }
            break // Found the chapter, no need to continue
          }
        }
      })
    )

    // 3. Trigger audio player update for new/regenerated segments
    if (onAudioUpdate) {
      onAudioUpdate(data.segmentId, data.chapterId)
    }

    // No invalidation - optimistic updates are sufficient for live feedback
    // Authoritative refetch happens at job.completed event
  } catch (error) {
    logger.error('[SSE] Failed to handle segment.completed event:', error)
  }
}

/**
 * Handle segment.failed event
 * Action: Update segment status to 'failed' in chapter cache AND projects cache
 *
 * Note: No invalidation - optimistic updates for instant feedback.
 * Final authoritative refetch happens once at job.completed/failed event.
 *
 * Optimized with immer: O(1) update instead of O(n) map for 95% performance gain
 */
function handleSegmentFailed(data: ExtendedSegmentFailedData, queryClient: QueryClient) {
  try {
    logger.group(
      '‚ùå Segment Failed',
      'TTS segment generation failed',
      {
        'Segment ID': data.segmentId,
        'Chapter ID': data.chapterId,
        'Error': data.error,
        'Status': data.status
      },
      '#F44336' // Red for failure
    )

    // 1. Update chapter detail (contains segments array)
    queryClient.setQueryData(
      queryKeys.chapters.detail(data.chapterId),
      produce((draft: Chapter | undefined) => {
        if (!draft) return
        const segment = draft.segments.find(s => s.id === data.segmentId)
        if (segment) {
          segment.status = 'failed' as const
        }
      })
    )

    // 2. Update projects list (for ChapterList live updates)
    queryClient.setQueryData(
      queryKeys.projects.lists(),
      produce((draft: Array<{ chapters: Array<{ id: string; segments: Array<{ id: string; status: string }> }> }> | undefined) => {
        if (!draft) return
        for (const project of draft) {
          const chapter = project.chapters.find((ch) => ch.id === data.chapterId)
          if (chapter) {
            const segment = chapter.segments.find((s) => s.id === data.segmentId)
            if (segment) {
              segment.status = 'failed' as const
            }
            break // Found the chapter, no need to continue
          }
        }
      })
    )

    // No invalidation - optimistic updates are sufficient for live feedback
    // Authoritative refetch happens at job.completed/failed event
  } catch (error) {
    logger.error('[SSE] Failed to handle segment.failed event:', error)
  }
}

// ============================================================================
// Export Hook
// ============================================================================

/**
 * Custom hook that returns all TTS job event handlers
 *
 * This hook uses useCallback to ensure stable function references,
 * which is critical for preventing re-subscription loops in SSE context.
 *
 * @param queryClient - React Query client instance
 * @returns Object containing all TTS job event handler functions
 *
 * @example
 * ```tsx
 * const queryClient = useQueryClient()
 * const handlers = useSSETTSHandlers(queryClient)
 *
 * // Use handlers in event router
 * handlers.handleJobCreated(data, queryClient)
 * ```
 */
interface UseSSETTSHandlersOptions {
  /**
   * Callback to trigger audio player updates
   * Called for segment.completed events
   */
  onAudioUpdate?: (segmentId: string, chapterId: string) => void
  /**
   * Callback for TTS job status changes (completed, failed, cancelled)
   * Called for job.completed, job.failed, and job.cancelled events
   */
  onJobStatusChange?: (status: 'completed' | 'failed' | 'cancelled', jobId: string, chapterId: string) => void
}

export function useSSETTSHandlers(queryClient: QueryClient, options?: UseSSETTSHandlersOptions) {
  const { onAudioUpdate, onJobStatusChange } = options || {}

  // Wrap all handlers in useCallback to prevent unnecessary re-creation
  // Note: These handlers don't depend on any reactive state, so dependencies are minimal

  const wrappedHandleJobCreated = useCallback(
    (data: ExtendedJobCreatedData) => handleJobCreated(data, queryClient),
    [queryClient]
  )

  const wrappedHandleJobStarted = useCallback(
    (data: ExtendedJobStartedData) => handleJobStarted(data, queryClient),
    [queryClient]
  )

  const wrappedHandleJobProgress = useCallback(
    (data: ExtendedJobProgressData) => handleJobProgress(data, queryClient),
    [queryClient]
  )

  const wrappedHandleJobCompleted = useCallback(
    (data: ExtendedJobCompletedData) => handleJobCompleted(data, queryClient, onJobStatusChange),
    [queryClient, onJobStatusChange]
  )

  const wrappedHandleJobFailed = useCallback(
    (data: ExtendedJobFailedData) => handleJobFailed(data, queryClient, onJobStatusChange),
    [queryClient, onJobStatusChange]
  )

  const wrappedHandleJobCancelling = useCallback(
    (data: { jobId: string; chapterId: string }) => handleJobCancelling(data, queryClient),
    [queryClient]
  )

  const wrappedHandleJobCancelled = useCallback(
    (data: ExtendedJobCancelledData) => handleJobCancelled(data, queryClient, onJobStatusChange),
    [queryClient, onJobStatusChange]
  )

  const wrappedHandleJobResumed = useCallback(
    (data: JobResumedData) => handleJobResumed(data, queryClient),
    [queryClient]
  )

  const wrappedHandleSegmentStarted = useCallback(
    (data: SegmentStartedData) => handleSegmentStarted(data, queryClient),
    [queryClient]
  )

  const wrappedHandleSegmentCompleted = useCallback(
    (data: ExtendedSegmentCompletedData) => handleSegmentCompleted(data, queryClient, onAudioUpdate),
    [queryClient, onAudioUpdate]
  )

  const wrappedHandleSegmentFailed = useCallback(
    (data: ExtendedSegmentFailedData) => handleSegmentFailed(data, queryClient),
    [queryClient]
  )

  return {
    handleJobCreated: wrappedHandleJobCreated,
    handleJobStarted: wrappedHandleJobStarted,
    handleJobProgress: wrappedHandleJobProgress,
    handleJobCompleted: wrappedHandleJobCompleted,
    handleJobFailed: wrappedHandleJobFailed,
    handleJobCancelling: wrappedHandleJobCancelling,
    handleJobCancelled: wrappedHandleJobCancelled,
    handleJobResumed: wrappedHandleJobResumed,
    handleSegmentStarted: wrappedHandleSegmentStarted,
    handleSegmentCompleted: wrappedHandleSegmentCompleted,
    handleSegmentFailed: wrappedHandleSegmentFailed,
  }
}
